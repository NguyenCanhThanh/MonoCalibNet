<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-10550309-8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-10550309-8');
</script>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-weight:300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
  <head>
        <title>M-Calib: A Monocular 3D Object Localization using 2D Estimates for Industrial Robot Vision System</title>
        <meta property="og:title" content="SE3HamDL" />
        <meta property="og:image" content="" />
        <meta property="og:url" content="" />
      <style>
code {
  font-family: Consolas,"courier new";
  color: darkcyan;
  background-color: #f1f1f1;
  padding: 2px;
  font-size: 105%;
}
</style>
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:42px">M-Calib: A Monocular 3D Object Localization using 2D Estimates for Industrial Robot Vision System</span>
    
    </center>

    <br><br>
      <table align=center width=1000px>
       <tr>
         <td align=center width=150px>
         <center>
         <span style="font-size:20px"><a href="https://thanhnguyencanh.github.io/">Thanh Nguyen Canh</a></span>
         </center>
         </td>

         <td align=center width=150px>
          <center>
          <span style="font-size:20px">Du Ngoc Trinh</span>
          </center>
          </td>

         <td align=center width=150px>
         <center>
         <span style="font-size:20px"><a href="https://sites.google.com/site/xiemhoang/home?authuser=0">Xiem HoangVan</a></span>
         </center>
         </td>
      
     </tr>
    </table>

    <table align=center width=700px>
       <tr>
        <td align=center width=100px>
        <center>
        <span style="font-size:20px">VNU University of Engineering and Technology, Vietnam <br/><a href="https://www.jamris.org/index.php/JAMRIS"> Journal of Automation, Mobile Robotics and Intelligent Systems (JAMRIS)</a>, 2025.</span>
        </center>
        </td>
     </tr>
    </table>

    <br>

    <table align=center width=500px>
     <tr>
       <td align=center width=100px>
       <center>
       <span style="font-size:20px"><a href="https://www.researchsquare.com/article/rs-4019542/v1">[Paper]</a></span>
       </center>
       </td>
       <td align=center width=100px>
       <center>
       <span style="font-size:20px"><a href="https://github.com/thanhnguyencanh/MonoCalibNet">[Code]</a></span>
       </center>
       </td>
    
   </tr>
  </table>

            <br>
            

            <br>
            3D Object Localization has been emerging recently as one of the challenges of Machine Vision or Robot Vision tasks. In this paper, we proposed a novel method designed for the localization of isometric flat 3D objects, leveraging a blend of deep learning techniques primarily rooted in object detection, postimage processing algorithms, and pose estimation. Our approach involves the strategic application of 3D calibration methods tailored for low-cost industrial robotics systems, requiring only a single 2D image input. Initially, object detection is performed using the You Only Look Once (YOLO) model, followed by segmentation of the object into two distinct parts— the top face and the remainder— using the Mask R-CNN model. Subsequently, the center of the top face serves as the initialization position and a unique combination of postprocessing techniques and a novel calibration algorithm is employed to refine the object’s position. Experimental results demonstrate a notable reduction in localization error by 87.65% when compared to existing methodologies.
            <br><br>

      <hr>
               <!-- <table align=center width=550px> -->
            <table align=center width=900>
             <center><h1>Paper</h1></center>
                <tr>
                    <!--<td width=300px align=left>-->
                    <!-- <a href="http://arxiv.org/pdf/1603.08511.pdf"> -->
                  <!-- <td><a href="#"><img class="layered-paper-big" style="height:175px" src="./resources/images/paper.png"/></a></td> -->
                  <td><a href="https://www.researchsquare.com/article/rs-4019542/v1"><img style="height:250px" src="images/thumbnails.png"/></a></td>
                  <td><span style="font-size:14pt">Thanh Nguyen Canh, Du Ngoc Trinh, Xiem HoangVan<br><br>
                    M-Calib: A Monocular 3D Object Localization using 2D Estimates for Industrial Robot Vision System<br><br>
                    JAMRIS 2025.<br><br>
                      <a href="https://www.researchsquare.com/article/rs-4019542/v1">[pdf]</a> &nbsp; &nbsp;
                   <!--    <a href="./resources/bibtex.txt">[Bibtex]</a> -->
                  <!-- [hosted on <a href="#">arXiv</a>]</a> -->
                    </td>
              </tr>
            </table>
      

         <!-- <table align=center width=550px> -->
            <table align=center width=800>
             <center><h1>Overview</h1></center>
                <tr>
                    <br>
<!--
            <td width=600px>
                      <center>
                          <span style="font-size:28px">Settings
                          <br>
                          <br>
                    </center>
                    </td>
-->
            <br>
            <table align=center width=900px>
                <tr>
                    <td width=900px>
                      <center>
                          <a href="images/Overview.png"><img src = "images/Overview.png" width="900px"></img></href></a><br>
                    </center>
                    </td>
                </tr>
                    <td width=900px>
                      <center>
                          <span style="font-size:18px"><i> A block diagram of our proposed calibration method. The translation vector between the initialized estimate center point (green point) and the calibration center point (red point) is calculated based on deep learning and our novel calibration method..</i>
                    </center>
                    </td>
                </tr>
            </table>
                    <br><br>
                    <table align=center width=900px>
                <tr>
                    <td width=600px>
                      <center>
                          <a href="images/problem.png"><img src = "images/problem.png" width="400px"></img></href></a><br>
                    </center>
                    </td>
                </tr>
                    <td width=900px>
                      <center>
                          <span style="font-size:18px"><i>Illustration of industrial robot vision system: the green point is the initialized estimate center point and the red point is the actual center point.</i>
                    </center>
                    </td>
                </tr>
            </table>

            <br><br>
                    <table align=center width=900px>
                <tr>
                    <td width=600px>
                      <center>
                          <a href="images/Alg1.png"><img src = "images/Alg1.png" width="440px"></img></href></a>
                          <a href="images/alg2.png"><img src = "images/alg2.png" width="440px"></img></href></a><br>
                    </center>
                    </td>
                </tr>
                    <td width=900px>
                      <center>
                          <span style="font-size:18px"><i>Estimate Translation Vector.</i>
                    </center>
                    </td>
                </tr>
            </table>
              
            <br>
            <table align=center width=800>
                
                <hr>
             <center><h1>Experiments</h1></center>
<!--
                <tr>
<table align=center width=900px>
                <tr>
                    <td width=900px>
                      <center>
                    <a href="./resources/gif/gym_state_control.gif"><img src = "./resources/gif/gym_state_control.gif" width="440px"></img></href></a>
                    <a href="./resources/gif/gym_animation_control.gif"><img src = "./resources/gif/gym_animation_control.gif" width="440px"></img></href></a>
                    
                    
                    <br>
                    </center>
                    </td>
                </tr>
                    <td width=900px>
                      <center>
                          <span style="font-size:18px"><i> For pendulum, we collect data by applying random control on a pendulum gym simulator. After learning the dynamics from data, we design an energy-based controller to drive the pendulum toward the upright position using the learned dynamics function.</i>
                    </center>
                    </td>
                </tr>
-->
            </table>
            <br><br>
                <table align=center width=900px>
                <tr>
                    <td width=900px>
                      <center>
                          <a href="images/objDet.png"><img src = "images/objDet.png" width="800px"></img></href></a><br>
<!--
                    <a href="./resources/gif/data1.gif"><img src = "./resources/gif/data1.gif" width="260px"></img></href></a>
                    <a href="./resources/gif/data2.gif"><img src = "./resources/gif/data2.gif" width="260px"></img></href></a>
                    <a href="./resources/gif/data2.gif"><img src = "./resources/gif/data11.gif" width="260px"></img></href></a>
                    <a href="./resources/gif/data2.gif"><img src = "./resources/gif/data15.gif" width="260px"></img></href></a>
                    <a href="./resources/gif/data2.gif"><img src = "./resources/gif/data14.gif" width="260px"></img></href></a>
                    <a href="./resources/gif/data2.gif"><img src = "./resources/gif/data13.gif" width="260px"></img></href></a>
                    <a href="./resources/gif/data2.gif"><img src = "./resources/gif/data18.gif" width="260px"></img></href></a>
                    <a href="./resources/gif/data2.gif"><img src = "./resources/gif/data21.gif" width="260px"></img></href></a>
                    <a href="./resources/gif/data2.gif"><img src = "./resources/gif/data4.gif" width="260px"></img></href></a>
-->
                <!-- <video  width="440" muted autoplay loop>
                <source src="resources/images/data_1.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
                         <a href="./resources/images/Drone1.jpg"><img src = "./resources/images/Drone1.jpg" width="440px"></img></href></a> 
                    <br>
                                          <video  width="440" muted autoplay loop>
                <source src="resources/images/data_2.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
                                          <video  width="440" muted autoplay loop>
                <source src="resources/images/data_3.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video> -->

                    </center>
                    </td>
                </tr>
                    <td width=900px>
                      <center>
                          <span style="font-size:18px"><i> The progress of calculation object position in real‐world coordinate.</i>
                    </center>
                    </td>
                </tr> 
            </table>

            <br><br>
            <table align=center width=600px>
            <tr>
                <td width=900px>
                  <center>
                      <a href="images/seg.png"><img src = "images/seg.png" width="800px"></img></href></a><br>
                </center>
                </td>
            </tr>
                <td width=900px>
                  <center>
                      <span style="font-size:18px"><i> The progress of object segmentation and edge extraction.</i>
                </center>
                </td>
            </tr>
            </table>

            <br><br>
            <table align=center width=600px>
            <tr>
                <td width=900px>
                  <center>
                      <a href="images/refine.png"><img src = "images/refine.png" width="500px"></img></href></a><br>
                </center>
                </td>
            </tr>
                <td width=900px>
                  <center>
                      <span style="font-size:18px"><i> Illustration of the estimate translation vector.</i>
                </center>
                </td>
            </tr>
            </table>

            <br><br>
            <table align=center width=600px>
            <tr>
                <td width=900px>
                  <center>
                      <a href="images/visual.png"><img src = "images/visual.png" width="800px"></img></href></a><br>
                </center>
                </td>
            </tr>
                <td width=900px>
                  <center>
                      <span style="font-size:18px"><i> 3D visual representation of the obtained semantic maps.</i>
                </center>
                </td>
            </tr>
        </table>

        <br><br>
            <table align=center width=600px>
            <tr>
                <td width=900px>
                  <center>
                      <a href="images/tab.png"><img src = "images/tab.png" width="500px"></img></href></a><br>
                </center>
                </td>
            </tr>
                <td width=900px>
                  <center>
                      <span style="font-size:18px"><i> Experimental results evaluate position error of our algorithm</i>
                </center>
                </td>
            </tr>
            </table>
            
        <hr>
         <center><h1>Code</h1></center>
            <table align=center width=800px>
              <tr><center> <br>
                <span style="font-size:28px">&nbsp;<a href='https://github.com/thanhnguyencanh/MonoCalibNet'>[github]</a>

                <span style="font-size:28px"></a></span>
              <br>
              </center></tr>
          </table>
            <br>
          <hr>

         <center><h1>Citation</h1></center>
            <table align=center width=800px>
              <!-- <tr><center> <br>
                          <span style="font-size:18px"><i>If you find our papers/code useful for your research, please cite our work as follows. </i>
                              <br>
              </center></tr>
              <tr><left> <br>
                          <span style="font-size:18px">1.  T. Duong, A. Altawaitan, J. Stanley, N. Atanasov. <a href='https://thaipduong.github.io/LieGroupHamDL/'>Port-Hamiltonian Neural ODE Networks on Lie Groups For Robot Dynamics Learning and Control</a>. under review, 2023.

                          
              <br><br>
                              <code>@article{duong23porthamiltonian, 
                                  <br>
                                    author    = {Thai Duong, Abdullah Altawaitan, Jason Stanley AND Nikolay Atanasov}, 
                                  <br>
                                    title     = {Port-{H}amiltonian Neural {ODE} Networks on Lie Groups For Robot Dynamics Learning and Control}, 
                                  <br>
                                    journal = {arXiv preprint arXiv:2401.09520}, 
                                  <br>
                                    year      = {2023}, 
                                  <br>

                                } 
                              </code>
              </left></tr>
                  <br>
              <br>
              </center></tr> -->
              <tr><left> <br>
                          <span style="font-size:18px">1.  Canh T. N., Ngoc D-T, HoangVan X., <a href='https://thanhnguyencanh.github.io/MonoCalibNet/'>M-Calib: A Monocular 3D Object Localization using 2D Estimates for Industrial Robot Vision System</a>. Journal of Automation, Mobile Robotics and Intelligent Systems (JAMRIS), 2025.

                          
              <br><br>
                              <code>@inproceedings{canh2025s3m, 
                                  <br>
                                    author    = {Canh, Thanh Nguyen and Ngoc, Du Trinh and HoangVan, Xiem}, 
                                  <br>
                                    title     = {{M-Calib: A Monocular 3D Object Localization using 2D Estimates for Industrial Robot Vision System}}, 
                                  <br>
                                    journal = {Journal of Automation, Mobile Robotics and Intelligent Systems (JAMRIS)}, 
                                  <br>
                                    year      = {2025}, 
                                  <br>
                                } 
                              </code>
              </left></tr>
                  <br><br>
              
          </table>
            <br>
          <hr>

            <table align=center width=1100px>
                <tr>
                    <td>
                      <left>
                <center><h1>Acknowledgements</h1></center>
                Thanh Nguyen Canh was funded by the Master, PhD Scholarship Programmer ofVingroup Innovation Foundation (VINIF), code VINIF.2023.ThS.120
                <br>
                This webpage template was borrowed from <a href="https://akanazawa.github.io/cmr/">https://akanazawa.github.io/cmr/</a>.
            </left>
        </td>
        </tr>
        </table>
<div style="display:inline-block;width:200px;"><script type="text/javascript" src="//rf.revolvermaps.com/0/0/7.js?i=5ho5yi7e4v7&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;sx=0" async="async"></script></div>

        <br><br>
</body>
</html>
